HW 5
================
Melanie Mayer
11/5/2018

Problem 1
---------

Below I will read in, merge, and tidy all the data.

``` r
#dataframe w/ all file names
file_names = list.files("./data/")

#merge all data frames, extract info wanted, tidy data
study_data = 
  tibble(file_names = str_c("./data/", file_names)) %>% 
  mutate(study_data = map(file_names, read_csv)) %>% 
  unnest() %>%
  separate(file_names, into = c("type", "subject"), sep = "_") %>%
  separate(subject, into = c("subject", "remove"), sep = "\\.") %>%
  separate(type, into = c("remove1", "remove2", "type"), sep = "/") %>%
  select(-c(remove, remove1, remove2)) %>%
  gather(key = week, value = obs, week_1:week_8) %>%
  separate(week, into = c("remove", "week"), sep = "_") %>%
  select(-c(remove)) %>%
  mutate(type = factor(type),
         subject = factor(subject),
         week = as.integer(week))

#assure process done correctly
head(study_data) %>%
  knitr::kable()
```

| type | subject |  week|   obs|
|:-----|:--------|-----:|-----:|
| con  | 01      |     1|  0.20|
| con  | 02      |     1|  1.13|
| con  | 03      |     1|  1.77|
| con  | 04      |     1|  1.04|
| con  | 05      |     1|  0.47|
| con  | 06      |     1|  2.37|

Below is a spaghetti plot showing observations on each subject over time.

``` r
study_data %>%
  mutate(type = fct_recode(type, "Control" = "con", "Experiment" = "exp")) %>%
  ggplot(aes(x = week, y = obs, color = subject)) + 
  geom_line() +
  ylab("Observation") +
  facet_grid(~type)
```

![](p8105_hw5_mm4963_files/figure-markdown_github/unnamed-chunk-2-1.png)

Looking at the spaghetti plots we can see the general trends of the experimental group compared to the control group. While the control group seems rather stagnant there does seem to be an upward trend in the experimental group. Because I do not know what we were testing, not much more can be said. There is a lot of variation from week to week, but comparing week one to week eight there is a rise in all 10 experimental subjects.

Problem 2
---------

Import and explore data

``` r
homicide_df = read_csv("https://raw.githubusercontent.com/washingtonpost/data-homicides/master/homicide-data.csv")
```

The dataset shows 52179 criminal homicides since 2007 in 50 of the largest cities in the USA. A total of 12 variables are used to describe the homicides. These include the following: For each homicide information is given on the victim's age, race, and sex. The location of the incident described by the city, state, and longitudinal/latitudinal point is specified. The outcome of the homicide, i.e. whether it resulted in an arrest, is also presented.

I will do some data manipulations below.

``` r
#create df with city_state, total number of homicides, and number of unsolved homicides variables

homicide_df_selected = homicide_df %>%
  mutate(city_state = str_c(city, ", ", state),
         disposition = factor(disposition)) %>%
  group_by(city_state, disposition) %>%
  mutate(total_per_disposition = n()) %>%
  select(c(city_state, disposition, total_per_disposition)) %>%
  distinct(city_state, disposition, .keep_all = T) %>%
  spread(key = disposition, value = total_per_disposition) %>%
  janitor::clean_names() %>%
  replace_na(list(closed_without_arrest = 0, open_no_arrest = 0, closed_by_arrest = 0)) %>%
  mutate(total_unsolved = closed_without_arrest + open_no_arrest,
         total_hom = closed_without_arrest + open_no_arrest + closed_by_arrest)
```

Now that I have the variables I am interested in I will run some tests.

I begin by estimating the proportion of homicides that are unsolved in Baltimore, MD.

``` r
#filter out Baltimore
baltimore_data = homicide_df_selected %>%
  filter(city_state == "Baltimore, MD")

#run test of proportion
baltimore_prop = prop.test(baltimore_data$total_unsolved, baltimore_data$total_hom) %>%
  broom::tidy() %>%
  select(c(estimate, conf.low, conf.high))

#View results
baltimore_prop %>%
  knitr::kable()
```

|   estimate|   conf.low|  conf.high|
|----------:|----------:|----------:|
|  0.6455607|  0.6275625|  0.6631599|

Next I will extend this test to all 50 (51 including Tulsa, AL) cities in the dataset.

``` r
#test for the proportion of unsolved homicides per city
prop_tests = homicide_df_selected %>%
  mutate(prop_output = map2(total_unsolved, total_hom, prop.test)) %>%
  mutate(prop_output = map(prop_output, broom::tidy)) %>%
  unnest() %>%
  select(c(city_state, estimate, conf.low, conf.high))
 

#view some results
head(prop_tests) %>% 
  knitr::kable()
```

| city\_state     |   estimate|   conf.low|  conf.high|
|:----------------|----------:|----------:|----------:|
| Albuquerque, NM |  0.3862434|  0.3372604|  0.4375766|
| Atlanta, GA     |  0.3833505|  0.3528119|  0.4148219|
| Baltimore, MD   |  0.6455607|  0.6275625|  0.6631599|
| Baton Rouge, LA |  0.4622642|  0.4141987|  0.5110240|
| Birmingham, AL  |  0.4337500|  0.3991889|  0.4689557|
| Boston, MA      |  0.5048860|  0.4646219|  0.5450881|

The plot below demonstrates the results found above.

``` r
#plot of confidence interval per city
#Tulsa, AL removed for purposes of the plot, only has one observation therefore very imprecise CI

prop_tests %>%
  ungroup(city_state) %>%
  filter(city_state != "Tulsa, AL") %>%
  mutate(city_state = fct_reorder(city_state, estimate)) %>%
  ggplot(aes(x = city_state, y = estimate)) +
    geom_point() + 
    geom_errorbar(aes(ymin = conf.low, ymax = conf.high)) +
    theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
    labs(x = "",
         y = "",
         title = "Proportion of Unsolved Homicides")
```

![](p8105_hw5_mm4963_files/figure-markdown_github/unnamed-chunk-7-1.png)
